{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this Notebook to Hear Piano Performances Created by your Model\n",
    "\n",
    "Use this notebook to generate, listen to, and save midi files of your models performances. Simply run the cells below in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from pianonet.core.note_array import NoteArray\n",
    "from pianonet.training_utils.master_note_array import MasterNoteArray\n",
    "from pianonet.training_utils.note_sample_generator import NoteSampleGenerator\n",
    "from pianonet.model_building.get_model_input_shape import get_model_input_shape\n",
    "import pianonet.model_inspection.performance_tools as pt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Seed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_note_array = MasterNoteArray(file_path='./pianonet_mini_dataset_0_validation.mna')\n",
    "note_array_transformer = master_note_array.note_array_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Trained Model\n",
    "\n",
    "Make sure model path is pointing to the most recent model. This could be 1_trained_model, for example, if you restarted training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = \"./\"\n",
    "model_path = \"models/0_trained_model\"\n",
    "\n",
    "model = load_model(os.path.join(run_path, model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a performance\n",
    "\n",
    "Set `use_seed = False` if you want to hear a performance where the model starts with silence. This removes any human influence. If `use_seed = True`, the model starts its state as seeing a history of notes from a random segment in the validation set.\n",
    "\n",
    "Increase `num_time_steps_in_performance` for longer performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing state queues.\n",
      "Resetting the state queues to the initial state (for a new performance).\n",
      "\n",
      "==> Time step 0 seconds of audio is 0\n",
      "==> Time step 48 seconds of audio is 1\n",
      "==> Time step 96 seconds of audio is 2\n",
      "==> Time step 144 seconds of audio is 3\n",
      "==> Time step 192 seconds of audio is 4\n",
      "==> Time step 240 seconds of audio is 5\n",
      "==> Time step 288 seconds of audio is 6\n",
      "\n",
      "Time per second of audio: 2.15 seconds\n",
      "Timesteps added: 300.0\n"
     ]
    }
   ],
   "source": [
    "use_seed = True\n",
    "num_time_steps_in_performance = 600\n",
    "\n",
    "num_time_steps_in_model_input = get_model_input_shape(model)/note_array_transformer.num_keys\n",
    "num_time_steps_in_seed = int(num_time_steps_in_model_input) + 24\n",
    "\n",
    "\n",
    "seed_note_array = master_note_array.get_note_array_from_random_segment_of_time_steps(num_time_steps=num_time_steps_in_seed)\n",
    "\n",
    "if not use_seed:\n",
    "    seed_note_array.array = np.zeros((len(seed_note_array.array),)).astype('bool')    \n",
    "\n",
    "performance_note_array = pt.get_performance(model=model,\n",
    "                                            seed_note_array=seed_note_array,\n",
    "                                            num_time_steps=num_time_steps_in_performance,\n",
    "                                            validation_fraction=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play the Performance\n",
    "\n",
    "Context seconds is how much history is played back if a seed was used. Set to zero to hear where your model comes in. If you don't like how it sounds, add data or train longer! With enough data and training time, your model can sound like a pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = performance_note_array.get_pianoroll()\n",
    "\n",
    "context_seconds = 3\n",
    "\n",
    "if not use_seed:\n",
    "    p.trim_silence_off_ends()\n",
    "else:\n",
    "    num_input_time_steps = int(get_model_input_shape(model)/note_array_transformer.num_keys)    \n",
    "    p = p[max(0, num_input_time_steps-48*context_seconds):]\n",
    "    \n",
    "p.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Additional Timesteps to the Existing Performance\n",
    "\n",
    "The cell below will add more model predictions to the existing performance. After it completes, run the cell above to play the extended performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing state queues.\n",
      "Resetting the state queues to the initial state (for a new performance).\n",
      "\n",
      "==> Time step 0 seconds of audio is 0\n",
      "==> Time step 48 seconds of audio is 1\n",
      "==> Time step 96 seconds of audio is 2\n",
      "==> Time step 144 seconds of audio is 3\n",
      "==> Time step 192 seconds of audio is 4\n",
      "==> Time step 240 seconds of audio is 5\n",
      "==> Time step 288 seconds of audio is 6\n",
      "==> Time step 336 seconds of audio is 7\n",
      "==> Time step 384 seconds of audio is 8\n",
      "==> Time step 432 seconds of audio is 9\n",
      "==> Time step 480 seconds of audio is 10\n",
      "==> Time step 528 seconds of audio is 11\n",
      "==> Time step 576 seconds of audio is 12\n",
      "\n",
      "Time per second of audio: 2.513 seconds\n",
      "Timesteps added: 600.0\n"
     ]
    }
   ],
   "source": [
    "num_time_steps_to_add = 600\n",
    "\n",
    "performance_note_array = pt.get_performance(model=model,\n",
    "                                            seed_note_array=performance_note_array,\n",
    "                                            num_time_steps=num_time_steps_to_add,\n",
    "                                            validation_fraction=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Performance as a Midi File\n",
    "\n",
    "If you like how it sounds, save it! That way you can show your friends. Midi files can be converted to mp3s using Garageband or online converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./my_models_awesome_performance.midi\"\n",
    "performance_note_array.get_pianoroll().save_to_midi_file(file_path=os.path.join(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
